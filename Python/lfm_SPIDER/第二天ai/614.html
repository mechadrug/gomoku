<!DOCTYPE html>
<html lang="zh">
<head>
	<meta http-equiv="X-UA-Compatible" content="IE=11,10,9,edge">
	<meta name="keywords" content="Gaoling School of Artificial Intelligence">
	<meta name="description" content="Gaoling School of Artificial Intelligence">
 	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,Chrome=1">
	<title>Gaoling School of Artificial Intelligence</title>
	<link rel="stylesheet" href="../../css/swiper_hha.css">
	<link rel="stylesheet" href="../../css/animate.css">
	<link rel="stylesheet" href="../../css/bootstrap.min.css">
<link rel="stylesheet" href="../../css/layout.css">
<link rel="stylesheet" href="../../css/menucss.css">
	<script src="../../js/jquery.min.js"></script>
	<script src="../../js/wow.min.js"></script>
	<script src="../../js/swiper-4.1.6.min.js"></script>
<script src="../../js/bootstrap.min.js"></script>
<script src="../../js/jQuery.autoIMG.js"></script>
<script src="https://cdn.bootcss.com/jquery-mousewheel/3.1.13/jquery.mousewheel.min.js"></script>
<script type="text/javascript"> 
	var browser={
	    versions:function(){
	        var u = navigator.userAgent, app = navigator.appVersion;
	        return {//移动终端浏览器版本信息
	            trident: u.indexOf('Trident') > -1, //IE内核
	            presto: u.indexOf('Presto') > -1, //opera内核
	            webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
	            gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
	            mobile: !!u.match(/AppleWebKit.*Mobile.*/)||u.indexOf('iPad') > -1, //是否为移动终端
	            ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
	            android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
	            iPhone: u.indexOf('iPhone') > -1, //是否为iPhone或者QQHD浏览器
	            iPad: u.indexOf('iPad') > -1, //是否iPad
	            webApp: u.indexOf('Safari') == -1 //是否web应该程序，没有头部与底部
	        };
	    }(),
	}
	if(browser.versions.android || browser.versions.iPhone){
var oMeta = document.createElement('meta');
                oMeta.name = 'viewport';
                oMeta.content = 'width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no';
                document.getElementsByTagName('head')[0].appendChild(oMeta);
	}
</script>

</head>
<body>

<!--========== HEADER ==========-->
        <header class="header">
            <!-- Navbar -->
            <nav class="navbar" role="navigation">
                <div class="container">
                    <!-- Brand and toggle get grouped for better mobile display -->
                    <div class="menu-container">
                        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="toggle-icon"></span>
                        </button>

                        <!-- Logo -->
                        <div class="navbar-logo">
                            <a class="navbar-logo-wrap" href="http://ai.ruc.edu.cn/english/index.htm">
                                <img class="navbar-logo-img" src="../../images/gsai_en_logo_white.png" >
                            </a>
                        </div>
                        <!-- End Logo -->
                    </div>

                    <!-- Collect the nav links, forms, and other content for toggling -->
                    <div class="collapse navbar-collapse nav-collapse">
                        <div class="menu-container">
                            <ul class="navbar-nav navbar-nav-right">
                                <!-- Home -->
                                <li class="nav-item">
                                    <a class="nav-item-child " href="../index.htm">
                                        Home
                                    </a>
                                </li>
                                <!-- End Home -->

                                <!-- About -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="../gsaiabout/introduction/index.htm">
                                        ABOUT US
                                    </a>
                                </li>
                                <!-- End About -->

                                <!-- Work -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="../GSAI_FACULTY/index.htm" >
                                        FACULTY & RESEARCH
                                    </a>
                                </li>
                                <!-- End Work -->

 <!-- Work -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="../academic/index.htm" >
                                        ACADEMIC
                                    </a>
                                </li>
                                <!-- End Work -->


                             <!-- Contact -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="index.htm">
                                        NEWS
                                    </a>
                                </li>
                                <!-- End Contact -->


								 <!-- Contact -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="../gsaijob/index.htm">
                                        JOB OPENING
                                    </a>
                                </li>
                                <!-- End Contact -->


								 <!-- Contact -->
                                <li class="nav-item">
                                    <a class="nav-item-child" style="color:#f4ca06" href="http://ai.ruc.edu.cn">
                                        CN(中文)
                                    </a>
                                </li>
                                <!-- End Contact -->
                            </ul>
                        </div>
                    </div>
                    <!-- End Navbar Collapse -->
                </div>
            </nav>
            <!-- Navbar -->
        </header>
        <!--========== END HEADER ==========--><!-- Features -->
<div class="body_bg" style="height: 200px">
    <div class="overlayer"></div>
    <div class="content-md container " style="height: 200px">
        <div class="row">
            <div class="col-sm-12 col-xs-12">
                <div class="text-white text-center"><h2 class="text-white">NEWS</h2></div>


            </div>
        </div>

    </div>
</div>
<!-- End Features -->

<!-- Work -->
<div class="pagecontent">
    <div class="container">
        <div class="row">
            <div class="col-xs-3 col-sm-3 hidden-xs">
               
<nav>
                        <div id="menu" class="white menu">
                            <div class="menu-header">MENU </div>
                            <ul>
                                <li  ><a  href="../index.htm">HOME</a></li>
                                <li><a href="#">ABOUT US</a>
                                    <ul class="submenu">
                                        <li ><a href="../gsaiabout/introduction/index.htm"> INTRODUCTION</a></li>
                                        <li ><a href="../gsaiabout/administrators/index.htm"> CURRENT ADMINISTRATORS</a></li>
                                    </ul>
                                </li>
                                <li ><a href="../GSAI_FACULTY/index.htm">FACULTY & RESEARCH</a></li>
                                <li ><a href="../academic/index.htm">ACADEMIC</a></li>
                                <li  class="active" ><a href="index.htm">NEWS</a></li>
                                <li ><a href="../gsaijob/index.htm">JOB OPENING</a></li>
                            </ul>
                          
                        </div>
                    </nav>

<!--
<div class="leftmenu">
</div>-->            </div>
            <div class="col-xs-12 col-sm-9">
                <div class="articlecontent">
                     <div style="font-size:14px;"><i class="fa fa-bank"></i> 
 				<a href="../index.htm">GSAIHOME<span style="margin-left:10px;margin-right:10px">/</span></a>
				<a href="index.htm">NEWS<span style="margin-left:10px;margin-right:10px">/</span></a>
				</div>
                <div class="articletitle"><h2>Six papers from GSAI accepted by CCF A-category Conference ACL</h2><small><span></span></small>

<div style="text-align:center;margin-top:10px"><span>Date：2021-06-12</span>  <span style="margin-left:20px">Visits：<span id="visit_count"  style="padding:0;"><script src="/wm/api/visit/get/article?siteID=b789c5741b814b2998e36b9a58c98f96&articleID=f2b2ae7bf8b34a6095fbb5056789ba94" async>
</script>
</span></div></div>
                 <div class="articlecontent" id="desc">
                   <p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;">Six papers by faculty and students from Gaoling School of Artificial Intelligence, Renmin University of China (GSAI), were recently accepted by Annual Meeting of the Association for Computational Linguistics (ACL). ACL is the most important top international conference in the field of computational linguistics and natural language processing, and it is a Category A international academic conference recommended by the China Computer Federation (CCF). ACL 2021 will be held in Bangkok, Thailand from August 1 to 6.</p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;">Since January 2021, GSAI has published (including those being accepted) 43 papers in CCF A-category international journals or conferences, 5 papers in CCF B-category journals and conferences. Among them, 46 papers have GSAI students or faculties listed as their first or corresponding authors.</p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Introduction (ACL Main Conference)</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Title: Enabling Lightweight Fine-tuning for Pre-trained Language Model Compression based on Matrix Product Operators</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Authors: Peiyu Liu, Zefeng Gao, Xin Zhao, Zhiyuan Xie, Zhongyi Lu, Jirong Wen</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Corresponding Authors: Xin Zhao, Zhongyi Lu</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Overview:</strong> Based on the matrix product operator (MPO) representation method in quantum many-body physics problems, this paper proposes a novel pre-training language model compression method. MPO means that the weight matrix can be expressed as the product of the intermediate tensor (containing the main information) and the auxiliary tensor (containing very few parameters). Based on this, we use the MPO representation of the matrix to propose a novel fine-tuning strategy, which only needs to update the auxiliary tensor containing very few parameters to update the overall weight matrix. At the same time, we also designed a new optimization method to train the multi-layer network structure under the MPO table. In addition, the method proposed in this paper is universal. Whether it is the original model or the compressed model, it can greatly reduce the amount of parameters that need to be fine-tuned. The experiments in this article also illustrate the effectiveness of this method in model compression, and ultimately reduce the amount of parameters to be fine-tuned by an average of 91%.</p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Introduction (ACL Main Conference)</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Title: A Joint Model for Dropped Pronoun Recovery and Conversational Discourse Parsing in Chinese Conversational Speech</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Authors: Jingxuan Yang, Kerui Xu, Jun Xu, Si Li, Sheng Gao, Jun Guo, Nianwen Xue, Jirong Wen</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Corresponding author: Jun Xu</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Abstract:</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;">In this paper, we present a neural model for joint dropped pronoun recovery (DPR) and conversational discourse parsing (CDP) in Chinese conversational speech. We show that DPR and CDP are closely related, and a joint model benefits both tasks. We refer to our model as DiscProReco, and it first encodes the tokens in each utterance in a conversation with a directed Graph Convolutional Network (GCN). The token states for an utterance are then aggregated to produce a single state for each utterance. The utterance states are then fed into a biaffine classifier to construct a conversational discourse graph. A second (multi-relational) GCN is then applied to the utterance states to produce a discourse relation-augmented representation for the utterances, which are then fused together with token states in each utterance as input to a dropped pronoun recovery layer. The joint model is trained and evaluated on a new Structure Parsing-enhanced Dropped Pronoun Recovery (SPDPR) data set that we annotated with both two types of information. Experimental</p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;">results on the SPDPR dataset and other benchmarks show that DiscProReco significantly outperformed the state-of-the-art baselines of both tasks.</p><p style="text-align: justify; text-indent: 0em;"><img src="../../images/2021-06/ffede2650e15451daa5542df0a53975a.png" title="ffede2650e15451daa5542df0a53975a.png" alt="1.png"/></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Introduction (ACL Main Conference)</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Title: A Pre-training Strategy for Zero-Resource Response Selection in Knowledge-Grounded Conversations</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Authors: Chongyang Tao, Changyu Chen, Jiazhan Feng, Jirong Wen, Rui Yan</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Corresponding author: Rui Yan</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Overview: </strong>In recent years, many researches on search dialogue systems are focusing on how to effectively use background knowledge (such as documents, etc.) when talking with humans. However, it is not easy to collect large-scale data sets for dialogue based on specific background documents, which hinders us from effectively and adequately training the knowledge selection module and response selection module in the system. In order to overcome this challenge, we decompose the training of response selection based on knowledge into three tasks: 1) matching of query and document; 2) matching of question and dialogue history; 3) matching of responses in multiple rounds of dialogue, and unifying all these tasks in the pre-trained language model. The first two tasks can help the model to select and understand knowledge, while the last task allows the model to select an appropriate response after a given query and background knowledge (conversation history). In this way, the model can use ad-hoc retrieval data and a large amount of natural multi-round dialogue data to learn how to select relevant knowledge and appropriate responses. We have conducted experiments on two benchmarks based on knowledge to conduct dialogues. The results show that compared with the existing training methods based on crowdsourced data, this model can achieve a considerable improvement in effect.</p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Introduction (ACL Findings)</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Title: Few-shot Knowledge Graph-to-Text Generation with Pretrained Language Models</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Authors: Junyi Li, Tianyi Tang, Xin Zhao, Zhicheng Wei, Jing Yuan, Jirong Wen</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Corresponding author: Xin Zhao</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Overview:</strong> This paper studies how to automatically generate natural language text describing the facts in the Knowledge Graph (KG). With the help of pre-trained language models (PLMs) in language understanding and generation, we mainly consider few-shot settings. We propose three main technical contributions, namely, representation alignment for bridging the semantic gap between KG encoding and PLM, relation-biased KG linearization strategy for generating better input representations, and multi-task learning for learning the correspondence between KG and text. &nbsp;﻿Extensive experiments on three benchmark datasets have demonstrated the effectiveness of our model on KG-to-text generation task. In particular, our model outperforms all comparison methods on both fully-supervised and fewshot settings.</p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Introduction (ACL Findings)</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Title: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Authors: Ruiyang Ren, Shangwen Lv, Yingqi Qu, Jing Liu, Xin Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Jirong Wen</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Corresponding Authors: Liu Jing, Zhao Xin</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Overview: </strong>Recently, dense passage retrieval has become a mainstream approach to ﬁnding relevant information in various natural language processing tasks. A number of studies have been devoted to improving the widely adopted dual-encoder architecture. However, most of the previous studies only consider query-centric similarity relation when learning the dual-encoder retriever. In order to capture more comprehensive similarity relations, we propose a novel approach that leverages both query-centric and PAssage-centric sImilarity Relations (called PAIR) for dense passage retrieval. To implement our approach, we make three major technical contributions by introducing formal formulations of the two kinds of similarity relations, generating high-quality pseudo labeled data via knowledge distillation, and designing an effective two-stage training procedure that incorporates passage-centric similarity relation constraint. Extensive experiments show that our approach signiﬁcantly outperforms previous state-of-the-art models on both MSMARCO and Natural Questions datasets.</p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Introduction (ACL Findings)</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Title: Enhancing the Open-Domain Dialogue Evaluation in Latent Space</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Authors: Zhangming Chan, Lemao Liu, Juntao Li, Haisong Zhang, Dongyan Zhao, Shuming Shi, Rui Yan</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Corresponding author: Rui Yan</strong></p><p style="line-height: 180%; font-size: 14pt; text-indent: 0em; text-align: justify;"><strong>Paper Overview: </strong>The &quot;one-to-many&quot; feature of open domain dialogue makes the design of its automatic evaluation method a huge challenge. Recent research attempts to solve this problem by directly considering the degree of matching between the generated replies and the context of the conversation, and using a discriminant model to learn from multiple positive samples. Despite the exciting progress made by such methods, they cannot be applied to training data that does not have multiple reasonable responses, which is the general case of real-world data sets. To this end, we propose a dialogue evaluation indicator enhanced through hidden space modeling-EMS. Specifically, we use self-supervised learning to obtain a smooth hidden space, which can not only extract the contextual information of the dialogue, but also model the possible reasonable responses to the context. Then we use the information captured in the hidden space to enhance the dialogue evaluation process. The experimental results on two real-world dialogue datasets prove the superiority of our method, in which the Pearson and Spearman correlation scores related to human judgment outperform all baseline models.</p> 
                </div>
                </div>

            </div>
        </div>
    </div>
</div>

<!--========== FOOTER ==========-->
        <footer class="footer">
            <!-- Links -->
                <div class="content container">
                    <div class="row">
                        <div class="col-sm-4 col-xs-12 sm-margin-b-30 hidden-xs">
                            <img src="../../images/gsai_en_logo_white.png" style="height:60px">
                        </div>

                        <div class="col-sm-5 col-xs-12">
                            <!-- List -->
                            <ul class="list-unstyled footer-list">
                                <li class="footer-list-item">Email: <a href="#">gsai@ruc.edu.cn</a></li>
                                <li class="footer-list-item">Mobile: <a href="#">86-10-62511257</a></li>
                            </ul>
                            <!-- End List -->
                        </div>
                        <div class="col-sm-3 col-xs-12">
                            <!-- List -->
                            <ul class="list-unstyled footer-list">
                                    <li class="footer-list-item">Copyright©2020 Gaoling School of <br>Artificial Intelligence</li>
                            </ul>
                            <!-- End List -->
                        </div>
                    </div>
                    <!--// end row -->
                </div>
  
            <!-- End Links -->
        </footer>
        <!--========== END FOOTER ==========-->

        <!-- Back To Top -->
        <a href="javascript:void(0);" class="js-back-to-top back-to-top">Top</a>
<script src="../../js/menuscript.js"></script>
<script>
$(function(){
		$("#desc").autoIMG();
	});
</script>

<script>	
	window.onload=function(){  
		
	}			
	</script>
<script type="text/javascript">
	jQuery.ajax({
		url: '/wm/api/visit/write/article',
		type: 'get',
		data: {
			siteID: 'b789c5741b814b2998e36b9a58c98f96',
			articleID:'f2b2ae7bf8b34a6095fbb5056789ba94',
			articleName:encodeURIComponent("Six papers from GSAI accepted by CCF A-category Conference ACL")
		}
	})
</script>

    </body>
</html><script type='text/javascript' src='../../g_style/g_article.js'></script>
</body></html>