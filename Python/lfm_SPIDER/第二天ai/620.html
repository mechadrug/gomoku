<!DOCTYPE html>
<html lang="zh">
<head>
	<meta http-equiv="X-UA-Compatible" content="IE=11,10,9,edge">
	<meta name="keywords" content="Gaoling School of Artificial Intelligence">
	<meta name="description" content="Gaoling School of Artificial Intelligence">
 	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,Chrome=1">
	<title>Gaoling School of Artificial Intelligence</title>
	<link rel="stylesheet" href="../../css/swiper_hha.css">
	<link rel="stylesheet" href="../../css/animate.css">
	<link rel="stylesheet" href="../../css/bootstrap.min.css">
<link rel="stylesheet" href="../../css/layout.css">
<link rel="stylesheet" href="../../css/menucss.css">
	<script src="../../js/jquery.min.js"></script>
	<script src="../../js/wow.min.js"></script>
	<script src="../../js/swiper-4.1.6.min.js"></script>
<script src="../../js/bootstrap.min.js"></script>
<script src="../../js/jQuery.autoIMG.js"></script>
<script src="https://cdn.bootcss.com/jquery-mousewheel/3.1.13/jquery.mousewheel.min.js"></script>
<script type="text/javascript"> 
	var browser={
	    versions:function(){
	        var u = navigator.userAgent, app = navigator.appVersion;
	        return {//移动终端浏览器版本信息
	            trident: u.indexOf('Trident') > -1, //IE内核
	            presto: u.indexOf('Presto') > -1, //opera内核
	            webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
	            gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
	            mobile: !!u.match(/AppleWebKit.*Mobile.*/)||u.indexOf('iPad') > -1, //是否为移动终端
	            ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
	            android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
	            iPhone: u.indexOf('iPhone') > -1, //是否为iPhone或者QQHD浏览器
	            iPad: u.indexOf('iPad') > -1, //是否iPad
	            webApp: u.indexOf('Safari') == -1 //是否web应该程序，没有头部与底部
	        };
	    }(),
	}
	if(browser.versions.android || browser.versions.iPhone){
var oMeta = document.createElement('meta');
                oMeta.name = 'viewport';
                oMeta.content = 'width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no';
                document.getElementsByTagName('head')[0].appendChild(oMeta);
	}
</script>

</head>
<body>

<!--========== HEADER ==========-->
        <header class="header">
            <!-- Navbar -->
            <nav class="navbar" role="navigation">
                <div class="container">
                    <!-- Brand and toggle get grouped for better mobile display -->
                    <div class="menu-container">
                        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="toggle-icon"></span>
                        </button>

                        <!-- Logo -->
                        <div class="navbar-logo">
                            <a class="navbar-logo-wrap" href="http://ai.ruc.edu.cn/english/index.htm">
                                <img class="navbar-logo-img" src="../../images/gsai_en_logo_white.png" >
                            </a>
                        </div>
                        <!-- End Logo -->
                    </div>

                    <!-- Collect the nav links, forms, and other content for toggling -->
                    <div class="collapse navbar-collapse nav-collapse">
                        <div class="menu-container">
                            <ul class="navbar-nav navbar-nav-right">
                                <!-- Home -->
                                <li class="nav-item">
                                    <a class="nav-item-child " href="../index.htm">
                                        Home
                                    </a>
                                </li>
                                <!-- End Home -->

                                <!-- About -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="../gsaiabout/introduction/index.htm">
                                        ABOUT US
                                    </a>
                                </li>
                                <!-- End About -->

                                <!-- Work -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="../GSAI_FACULTY/index.htm" >
                                        FACULTY & RESEARCH
                                    </a>
                                </li>
                                <!-- End Work -->

 <!-- Work -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="../academic/index.htm" >
                                        ACADEMIC
                                    </a>
                                </li>
                                <!-- End Work -->


                             <!-- Contact -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="index.htm">
                                        NEWS
                                    </a>
                                </li>
                                <!-- End Contact -->


								 <!-- Contact -->
                                <li class="nav-item">
                                    <a class="nav-item-child" href="../gsaijob/index.htm">
                                        JOB OPENING
                                    </a>
                                </li>
                                <!-- End Contact -->


								 <!-- Contact -->
                                <li class="nav-item">
                                    <a class="nav-item-child" style="color:#f4ca06" href="http://ai.ruc.edu.cn">
                                        CN(中文)
                                    </a>
                                </li>
                                <!-- End Contact -->
                            </ul>
                        </div>
                    </div>
                    <!-- End Navbar Collapse -->
                </div>
            </nav>
            <!-- Navbar -->
        </header>
        <!--========== END HEADER ==========--><!-- Features -->
<div class="body_bg" style="height: 200px">
    <div class="overlayer"></div>
    <div class="content-md container " style="height: 200px">
        <div class="row">
            <div class="col-sm-12 col-xs-12">
                <div class="text-white text-center"><h2 class="text-white">NEWS</h2></div>


            </div>
        </div>

    </div>
</div>
<!-- End Features -->

<!-- Work -->
<div class="pagecontent">
    <div class="container">
        <div class="row">
            <div class="col-xs-3 col-sm-3 hidden-xs">
               
<nav>
                        <div id="menu" class="white menu">
                            <div class="menu-header">MENU </div>
                            <ul>
                                <li  ><a  href="../index.htm">HOME</a></li>
                                <li><a href="#">ABOUT US</a>
                                    <ul class="submenu">
                                        <li ><a href="../gsaiabout/introduction/index.htm"> INTRODUCTION</a></li>
                                        <li ><a href="../gsaiabout/administrators/index.htm"> CURRENT ADMINISTRATORS</a></li>
                                    </ul>
                                </li>
                                <li ><a href="../GSAI_FACULTY/index.htm">FACULTY & RESEARCH</a></li>
                                <li ><a href="../academic/index.htm">ACADEMIC</a></li>
                                <li  class="active" ><a href="index.htm">NEWS</a></li>
                                <li ><a href="../gsaijob/index.htm">JOB OPENING</a></li>
                            </ul>
                          
                        </div>
                    </nav>

<!--
<div class="leftmenu">
</div>-->            </div>
            <div class="col-xs-12 col-sm-9">
                <div class="articlecontent">
                     <div style="font-size:14px;"><i class="fa fa-bank"></i> 
 				<a href="../index.htm">GSAIHOME<span style="margin-left:10px;margin-right:10px">/</span></a>
				<a href="index.htm">NEWS<span style="margin-left:10px;margin-right:10px">/</span></a>
				</div>
                <div class="articletitle"><h2>Upcoming Event | Joint Workshop on Adcances in Al</h2><small><span></span></small>

<div style="text-align:center;margin-top:10px"><span>Date：2023-03-05</span>  <span style="margin-left:20px">Visits：<span id="visit_count"  style="padding:0;"><script src="/wm/api/visit/get/article?siteID=b789c5741b814b2998e36b9a58c98f96&articleID=d6886bd0d67445e6980555c9f7ecb7fe" async>
</script>
</span></div></div>
                 <div class="articlecontent" id="desc">
                   <p style="line-height:180%;font-size:14pt;text-align:center;text-indent:0em"><br></p> 
<p style="line-height:180%;font-size:14pt;text-align:center;text-indent:0em"><span style="font-size:20px"><strong><img src="../../images/2023-03/41d9f6d1aa10443096cfb96ad345eca2.jpg" alt="微信图片_20230305194528.jpg"></strong></span></p> 
<p style="line-height:180%;font-size:14pt;text-indent:0em;text-align:center"><strong>Joint Workshop on Advances in AI&nbsp;</strong></p> 
<p style="line-height:180%;font-size:14pt;text-indent:0em;text-align:center"><strong>AIGC—From Beingless to Being</strong></p> 
<p style="line-height:180%;text-indent:2em;font-size:14pt;text-align:justify"><span style="font-size:20px">This year, we have decided to focus on dialog Generation model and multimedia content generation given the tremendous development of AI content generation in the past year, the theme of this workshop is AIGC : From Beingless to Being. We aim to bring together scientists, scholars and practitioners to discuss some of the most pressing issues with today.</span></p> 
<p style="line-height:180%;font-size:14pt;text-align:center;text-indent:0em"><span style="font-size:20px"><strong>Host by</strong></span></p> 
<p style="line-height:180%;text-indent:2em;font-size:14pt;text-align:center"><span style="font-size:20px">Gaoling School of Artificial Intelligence, Renmin University, China</span></p> 
<p style="line-height:180%;font-size:14pt;text-align:center;text-indent:0em"><span style="font-size:20px">Sunday, March 12, 2023</span></p> 
<p style="text-align:center;text-indent:0px"><img src="../../images/2023-03/f77bede1a8c74a398334ddcbda28a99e.jpeg" width="151" height="150"></p> 
<p style="line-height:180%;font-size:14pt;text-align:center;text-indent:0em"><span style="font-size:20px"><strong>Scan the QR code for sign up</strong></span></p> 
<p style="line-height:180%;text-indent:2em;font-size:14pt"><br></p> 
<p style="line-height:180%;text-indent:2em;font-size:14pt;text-align:center"><span style="font-size:20px"><strong>AGENDA (<span style="color:rgb( 255 , 0 , 0 );font-size:20px">tentative</span>)</strong></span></p> 
<table cellspacing="0" style="line-height:180%;font-size:14pt"> 
 <tbody> 
  <tr style="height:4px" class="firstRow"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">09:00-09:10</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Opening Remark</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Prof. Ji-Rong WEN</strong></span><span style="font-size:20px">,Executive Dean of Gaoling School of Artificial Intelligence (GSAI), Renmin University of China</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Moderator</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Prof. Hao SUN</strong></span><span style="font-size:20px">, Tenured Associate Professor, GSAI</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Session I</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Chat and Language</strong></span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">09:15-09:45</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title：A Coarse Analysis of ChatGPT</strong></span></p><p><span style="font-size:20px"><strong>Abstract</strong>：On December 1st last year, OpenAI launched ChatGPT, a new generation of conversational AI tool. ChatGPT has gained a lot of attention and buzz across the Internet for its amazing language understanding, generation and knowledge reasoning capabilities. The successful performance of ChatGPT has shown a possible path to solve Natural Language Processing, the core problem of cognitive intelligence. ChatGPT is considered a solid step towards the Artificial General Intelligence (AGI). ChatGPT will pose a huge challenge to applications such as search engines, and will even replace many people's jobs and disrupt many fields and industries. So, what scientific problem does ChatGPT solve, how does it solve that problem, and what other pressing problems will be solved in the future? We hope that the coarse analysis in this talk will partially answer these questions.</span></p><p><span style="font-size:20px"><strong>Prof. Wanxiang CHE</strong>, Professor, School of Computer Science and Technology, Harbin Institute of Technology</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><span style="color:rgb( 12 , 12 , 12 )"><strong style="font-size:20px;white-space:normal">Q&amp;A</strong></span></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr> 
   <td valign="top" colspan="1" rowspan="1" style="border-color:rgb( 0 , 0 , 0 );border-width:1px;border-style:solid;padding:2px 3px"><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">09:45-10:15</span></td> 
   <td valign="top" colspan="1" rowspan="1" style="border-color:rgb( 0 , 0 , 0 );border-width:1px;border-style:solid;padding:2px 3px"><br></td> 
   <td valign="top" colspan="1" rowspan="1" style="border-color:rgb( 0 , 0 , 0 );border-width:1px;border-style:solid;padding:2px 3px"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title: Discussion on the Generalization of Large Language Model</strong></span></p><p><strong style="color:rgb( 12 , 12 , 12 );font-size:20px;white-space:normal">Abstract</strong><span style="color:rgb( 12 , 12 , 12 );font-size:20px">：</span><span style="font-size:20px">Large language models such as ChatGPT demonstrate powerful generality, as they can understand various user intents and complete multiple tasks. Their generality is mainly driven by the foundation model, instruction learning, and prompt learning. However, the generality of large models is still limited by the type, scale, and quality of training data, making it difficult to achieve a more comprehensive generality. In this report, We will first discuss the performance of large language models in terms of their generality, then introduce current enhancement techniques to expand the generality, and finally briefly share our attempts and explorations in this regard.</span></p><p style="line-height:114%"><strong> </strong></p><p><span style="font-size:20px"><strong>Prof. Jiajun ZHANG</strong></span><span style="font-size:14pt">, </span><span style="font-size:20px">Professor, National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences</span><br></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><strong style="color:rgb( 12 , 12 , 12 );white-space:normal;font-size:20px">Q&amp;A</strong></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">10:20-10:50</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title：Learning and Thinking on Conversational AI between Human and Computer</strong></span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Abstract</strong>：</span><span style="font-size:20px">Along with the emergence of ChatGPT, conversational AI has attracted unprecedented attention from both academia and industry. People now witness that the technology behind conversational AI is gradually accumulating, and resulting in fundamental changes. With deeper insights from researchers, it is possible to expect conversational AI in reality, not just Sci-Fi movies. This talk covers recent studies on topic modeling and data augmentation in dialogue systems, and also presents a brief introduction to ChatGPT as well as new challenges of conversational AI in the future.</span></p><p><span style="font-size:20px"><strong>Prof. Rui YAN</strong></span><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">, </span><span style="font-size:20px">Tenured Associate Professor, GSAI</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><strong style="color:rgb( 12 , 12 , 12 );white-space:normal;font-size:20px">Q&amp;A</strong></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">10:55-11:25</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title：The Changing Focus of Large Language Model &nbsp;Research</strong></span></p><p><span style="font-size:20px"><strong>Abstract</strong></span><strong><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">：</span></strong><span style="font-size:20px">In this talk, we will introduce changes in the research focus on natural language processing and large language models with technological development. We divide technological development into several stages, briefly introduce the research focus and main approaches of each stage, and focus on analyzing the important research directions in the current period of large language models.</span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Dr. Junlin ZHANG</strong>, </span><span style="font-size:20px">Researcher, Sina Weibo</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><strong style="color:rgb( 12 , 12 , 12 );white-space:normal;font-size:20px">Q&amp;A</strong></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">11:30-12:10</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Panel</strong></span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">12:30-13:30</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Luncheon</strong></span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Session II</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Multimedia Content Generation</strong></span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Moderator</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Prof. Di Hu</strong>, </span><span style="font-size:20px">Tenure-Track assistant professor, GSAI</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">13:30-14:00</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title: Breaking the Curse of Dimensionality in Generative Modeling: A Homotopic Approach</strong></span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Abstract</strong>：</span><span style="font-size:20px">Generative modeling for high-dimensional data, such as images and audio, is extremely challenging due to the curse of dimensionality. To overcome this difficulty, I introduce a homotopic approach inspired by numerical equation solving, which involves designing a homotopy of probability distributions that smoothly progresses from simple noise distribution to complex data distribution. I will present two families of approaches that rely on such homotopies: score-based diffusion models and consistency models. Both approaches use a differential equation to convert data to noise and learn to estimate the time reversal with deep neural networks. These models generate high-quality samples by following the homotopy from tractable distributions to the original data distribution, achieving state-of-the-art performance in many generative modeling benchmarks. They both allow for flexible neural network architectures and zero-shot image editing and exhibit complementary trade-offs.</span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Prof. Yang SONG</strong>, </span><span style="font-size:20px">Tenure-Track assistant professor, Caltech</span></p><p><span style="font-size:20px">Member of Technical Staff, OpenAI</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Q&amp;A</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">14:05-14:35</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title：AIGC Technology and Application in XR</strong></span></p><p><span style="font-size:20px"><strong>Abstract: </strong></span><span style="font-size:20px">In the past year, both XR and AIGC have developed rapidly. The development of XR is mainly due to the exploration of VR devices by many large companies, such as &nbsp;Quest by Meta, Pico by Bytedance, etc. Based on the popularity of these devices, XR has many application scenarios in the fields of &nbsp;live broadcasting, digital human, 3D content creation, etc. The explosion of AIGC technology will greatly improve the development of these topics. This talk mainly includes:</span></p><p><span style="font-size:20px">1 Introduction to application scenarios in XR</span></p><p><span style="font-size:20px">2 AIGC technology in these scenarios</span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Shilei WEN</strong>, </span><span style="font-size:20px">Researcher, Bytedance</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Q&amp;A</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">14:40-15:10</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><strong style="color:rgb( 12 , 12 , 12 );font-size:20px;white-space:normal">T</strong><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>itle:Beyond Temporal Activity Localization (TAL) in Long-Form Video</strong></span></p><p><span style="font-size:20px"></span></p><p style="text-align:justify;margin-bottom:0"><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Abstract: </strong></span><span style="font-size:20px">Temporal activity localization (TAL) is an important task in video understanding especially for long-form videos. While much research has advanced the methodology used in this task, I will give an overview of the remaining challenges that hinder further performance. Moreover, I will elaborate on a relatively new task for the long-form video domain that goes beyond TAL, namely video language grounding.</span></p><p><span style="font-size:20px"><strong>Prof. Bernard Ghanem</strong></span><span style="font-size:20px"><strong>,</strong></span><span style="font-size:20px;font-family:'arial' , 'verdana' , sans-serif;color:rgb( 85 , 85 , 85 );background-color:rgb( 255 , 255 , 255 )">Deputy Director, KAUST AI Initiative</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Q&amp;A</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">15:15-15:45</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title：AI for Music</strong></span></p><p><strong><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">Abstract：</span></strong><span style="font-size:20px">In this talk, I will introduce our two recent works about AIGC for music. 1) Given a video, a controllable music transformer model was proposed to generate music according to the user-specified music genre and instruments. &nbsp;2) We further introduced music theory knowledge into the music generation model, collected the first video-music symbol data set for training, and proposed a retrieval-based metric to evaluate the matching degree between the generated music and video.</span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Prof. Si LIU</strong>, </span><span style="font-size:20px">Professor, Beihang University</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Q&amp;A</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">15:50-16:20</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title:&nbsp;Imaginative AI on the EDGE: transforming species discovery, content creation, self-driving cars, emotional well-being, and more</strong></span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Abstract:</strong></span><span style="font-size:20px">&nbsp; Most existing AI learning methods can be categorized into supervised, semi-supervised, and unsupervised methods. These approaches rely on defining empirical risks or losses on the provided labeled and/or unlabeled data. Beyond extracting learning signals from labeled/unlabeled training data, we will reflect in this talk on a class of methods that can learn beyond the vocabulary that was trained on and can compose or create novel concepts. Specifically, we address the question of how these AI skills may assist species discovery, content creation, self-driving cars, emotional health, and more. We refer to this class of techniques as imagination AI methods, and we will dive into how we developed several approaches to build machine learning methods that can See, Create, Drive, and Feel. See: recognize unseen visual concepts by imaginative learning signals and how that may extend in a continual setting where seen and unseen classes change dynamically. Create: generate novel art and fashion by creativity losses. Drive: improve trajectory forecasting for autonomous driving by modeling hallucinative driving intents. Feel: generate emotional descriptions of visual art that are metaphoric and go beyond grounded descriptions. Feel: generate emotional descriptions of visual art that are metaphoric and go beyond grounded descriptions, and how to build these AI systems to be more inclusive of multiple cultures. . I will also conclude by pointing out future directions where imaginative AI may help develop better assistive technology for multicultural and more inclusive metaverse, emotional health, and drug discovery.</span></p><p><span style="font-size:20px"><strong style="font-size:20px;white-space:normal">Prof. Mohamed Elhoseiny</strong><span style="font-size:20px">, Assistant Professor, Electrical and Mathematical Science and Engineering Division, KAUST</span></span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Q&amp;A</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">16:25-16:55</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title：Fast, Controllable and Multi-modal Diffusion Models Toward Generative AGI</strong></span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Abstract:</strong> </span><span style="font-size:20px">Diffusion models have shown promise in various generation tasks including image generation, text-to-image generation, 3D scene generation and speech generation. Such models provide fundamental tools to build generative AGI, which is expected to understand and generate multi-modal data via a user-friendly interface like ChatGPT. Toward building such generative AI systems, this talk presents recent advances in fast and controllable inference algorithms, as well as unified backbone and probabilistic framework for multi-modal diffusion models.</span></p><p><span style="font-size:20px"><strong>Prof. Chongxuan LI, </strong>Tenure-Track assistant professor, GSAI</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Q&amp;A</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">17:00-17:30</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Title: Modeling and Animating 2D Virtual Humans</strong></span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Abstract:</strong> </span><span style="font-size:20px">In recent years, 2D virtual humans have provided services in various scenarios including news reporting, teaching and entertainment. This talk gives an introduction to our recent advances in modeling and animating 2D virtual humans. For changing the appearance of virtual humans, I will introduce StyleSwap (ECCV 2022), which swaps and blends faces with high-fidelity. For face reenactment, I will introduce VPNQ (AAAI 2023) which drives virtual humans with videos. For audio-driven lip sync, I will introduce AV-CAT (Siggraph Asia 2022) and StyleSync (CVPR 2023), which seamlessly drive virtual humans to speak with audio.</span></p><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Dr. Hang ZHOU</strong>,</span><span style="font-size:20px">Researcher, Baidu</span></p></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">5mins</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Q&amp;A</strong></span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
  </tr> 
  <tr style="height:4px"> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )">17:35-18:15</span></p></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><br></td> 
   <td valign="top" style="padding:2px 3px;border:1px solid rgb( 0 , 0 , 0 )"><p><span style="font-size:20px;color:rgb( 12 , 12 , 12 )"><strong>Panel</strong></span></p></td> 
  </tr> 
 </tbody> 
</table> 
<p style="line-height:180%;text-indent:2em;font-size:14pt"><br></p> 
<p style="line-height:180%;text-indent:2em;font-size:14pt;text-align:center"><span style="font-size:24px"><strong>Speakers</strong></span></p> 
<p style="line-height:180%;text-indent:2em;font-size:14pt"><span style="font-size:20px"><strong>Speakers from Gaoling School of Artificial Intelligence, Renmin University, China</strong></span></p> 
<p style="line-height:180%;text-indent:2em;font-size:14pt"><span style="font-size:20px">See&nbsp;</span><a href="https://gsai.ruc.edu.cn/addons/teacher/enhome.html" style="text-decoration:underline;font-size:20px;color:rgb( 0 , 112 , 192 )" rel="nofollow"><span style="font-size:20px;color:rgb( 0 , 112 , 192 )">https://gsai.ruc.edu.cn/addons/teacher/enhome.html</span></a></p> 
<p style="text-align:center;text-indent:0px"><img src="../../images/2023-03/c9b38f76f2a347a380033ecc7f235f62.jpeg" width="110" height="110"></p> 
<p style="line-height:180%;text-indent:2em;font-size:14pt"><a href="http://ir.hit.edu.cn/~car/%20" style="text-decoration:underline;color:rgb( 84 , 141 , 212 );font-size:20px" rel="nofollow"></a></p> 
<p><a href="http://ir.hit.edu.cn/~car/" rel="nofollow"><span style="font-family:'times new roman';color:rgb( 5 , 99 , 193 );text-decoration:underline;font-size:20px">Prof. Wanxiang Che</span></a><span style="color:rgb( 5 , 99 , 193 );font-family:'times new roman';font-size:20px">&nbsp;</span><span style="text-indent:2em;font-size:20px">is a professor of School of Computer Science and Technology, Harbin Institute of Technology. He is the vice director of Research Center for Social Computing and Information Retrieval. He is a young scholar of “Heilongjiang Scholar” and a visiting scholar of Stanford University. He is currently the vice director and secretary-general of the Computational Linguistics Professional Committee of the Chinese Information Society of China; Officer and Secretary of AACL Executive Board; a senior member of the China Computer Federation (CCF).</span></p> 
<p style="text-align:center"><span style="text-indent:2em;font-size:20px"><img src="../../images/2023-03/0ed6c7e7eab640a69ebd48fdcc312d84.png" alt="" width="120" height="171" border="0" vspace="0" title="" style="width:120px;height:171px"></span></p> 
<p><a href="http://www.nlpr.ia.ac.cn/cip/jjzhang.htm" style="font-size:20px;text-decoration:underline" rel="nofollow"><span style="font-size:20px;text-decoration:underline"><span style="color:rgb( 5 , 99 , 193 );font-size:20px;font-family:'times new roman'">Pro</span><span style="font-size:20px;font-family:'times new roman';color:rgb( 5 , 99 , 193 )">f. Jiajun Zhang</span></span></a>&nbsp;<span style="text-indent:2em;font-size:20px">is a professor of National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences. His main research direction is machine translation and natural language processing. He has published more than 80 CCF-A/B papers, 2 academic monographs, 1 translation, 6 best/excellent paper awards, 3 outstanding SPC and reviewers of IJCAI, ACL and NAACL . He also won the first prize of the Qian Weichang Chinese Information Processing Science and Technology Award of the Chinese Information Processing Society of China, the first prize of the Youth Innovation Award, and the first prize of the 2020 Beijing Science and Technology Award. He serves as the (senior) area chair of ACL/EMNLP/COLING, and serves on the editorial boards of journals such as IEEE/ACM T-ASLP, ACM TALLIP etc.</span></p> 
<p><span style="text-indent:2em;font-size:20px"></span><br></p> 
<p style="text-align:center;text-indent:0px"><img src="../../images/2023-03/64aa23ea47a646e39d6cba99f3485fcc.jpeg" width="119" height="152"></p> 
<p style="font-size:14pt;text-align:justify;text-indent:0em"><span style="font-size:20px"><strong>Dr. Junlin Zhang&nbsp;</strong></span><span style="text-indent:2em;font-size:20px">is a researcher in Sina Weibo. He received the Ph.D. degree from the Institute of Software, Chinese Academy of Science. He was as a Senior Expert in SinaWeibo,Baidu, and Alibaba in past ten years. His current research interests include natural language processing, deep learning, and recommender systems.</span></p> 
<p style="text-align:center;text-indent:0px"><img src="../../images/2023-03/e2f7a82d777e41429f129dfd26c3a4d1.jpeg" width="111" height="167"></p> 
<p style="text-indent:2em;font-size:14pt;text-align:justify"><a href="https://yang-song.net/%20" style="text-decoration:underline;color:rgb( 84 , 141 , 212 );font-size:20px" rel="nofollow"></a></p> 
<p><a href="https://yang-song.net/" rel="nofollow"><span style="font-family:'times new roman';color:rgb( 5 , 99 , 193 );text-decoration:underline;font-size:20px">Prof. Yang Song</span></a><span style="color:rgb( 5 , 99 , 193 );font-family:'times new roman';font-size:20px">&nbsp;</span><span style="text-align:justify;text-indent:2em;font-size:20px">is the Tenure-Track assistant professor in Caltech. He is also a researcher in OpenAI. As a researcher in machine learning, he focused on developing scalable methods for modeling, analyzing and generating complex, high-dimensional data. His interest spans multiple areas, including generative modeling, representation learning, probabilistic inference, AI safety, and AI for science. His ultimate goal is to address problems that have wide-ranging significance, develop methods that are both accessible and effective, and build intelligent systems that can improve human lives.</span></p> 
<p style="text-align:center;text-indent:0px"><img src="../../images/2023-03/08633cdb5bf64036a1abfae0247401a8.png" width="104" height="154"></p> 
<p style="font-size:14pt;text-align:justify;text-indent:0em"><span style="font-size:20px"><strong>Shilei Wen</strong> is a researcher in Bytedance. He received the B.E. and M.E. degrees from the Huazhong University of Science and Technology, Wuhan, China, in 2007 and 2011, respectively. His research interests include image or video understanding, image or video retrieval, video surveillance, computer vision, and machine learning.</span></p> 
<p style="text-align:center;text-indent:0px"><img src="../../images/2023-03/454c340f12a745f3938c55a65d4dbaa9.jpeg" width="183" height="103"></p> 
<p style="text-indent:2em;font-size:14pt;text-align:justify"><a href="https://cemse.kaust.edu.sa/ivul/people/person/bernard-ghanem%20" style="text-decoration:underline;color:rgb( 84 , 141 , 212 );font-size:20px" rel="nofollow"></a></p> 
<p><a href="https://cemse.kaust.edu.sa/ivul/people/person/bernard-ghanem" rel="nofollow"><span style="font-family:'times new roman';color:rgb( 5 , 99 , 193 );text-decoration:underline;font-size:20px">Prof. Bernard Ghanem</span></a><span style="font-size:20px">&nbsp;</span><span style="font-size:20px">&nbsp;is currently a Professor of ECE and CS, a theme leader at the Visual Computing Center (VCC), and the Deputy Director of the AI Initiative at King Abdullah University of Science and Technology (KAUST) in Thuwal, Saudi Arabia. His research interests lie in computer vision and machine learning with emphasis on topics in video understanding, 3D recognition, and theoretical foundations of deep learning. He received his Bachelor’s degree from the American University of Beirut (AUB) in 2005 and his MS/PhD from the University of Illinois at Urbana-Champaign (UIUC) in 2010. His work has received several awards and honors, including several Best Paper Awards for workshops in CVPR/ECCV/ICCV, a Google Faculty Research Award in 2015 (1st in MENA for Machine Perception), and a Abdul Hameed Shoman Arab Researcher Award for Big Data and Machine Learning in 2020. He has co-authored more than 150 papers in his field. He serves as an Associate Editor for IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) and has served as Area Chair (AC) for the main computer vision and AI/ML conferences including CVPR, ICCV, ECCV, NeurIPS, ICLR, and AAAI.&nbsp;</span><span style="font-size:20px;text-align:justify">Visit ivul.kaust.edu.sa and <a href="http://www.bernardghanem.com" rel="nofollow">www.bernardghanem.com</a> for more details.</span></p> 
<p><span style="text-align:justify;text-indent:2em;font-size:20px"></span><br></p> 
<p style="text-align:center;text-indent:0px"><img src="../../images/2023-03/692959aaa90a487e8cbf21e23cc863a3.png" width="126" height="153"></p> 
<p style="text-indent:2em;font-size:14pt;text-align:justify"><a href="http://colalab.org/%20" style="text-decoration:underline;color:rgb( 84 , 141 , 212 );font-size:20px" rel="nofollow"></a></p> 
<p><a href="http://colalab.org/" rel="nofollow"><span style="font-family:'times new roman';color:rgb( 5 , 99 , 193 );text-decoration:underline;font-size:20px">Prof. Si</span></a><span style="font-size:20px"><span style="font-size:20px;text-decoration:underline"><span style="font-size:20px;font-family:'times new roman';color:rgb( 5 , 99 , 193 )"> L</span><span style="color:rgb( 5 , 99 , 193 );font-size:20px;font-family:'times new roman'">iu</span></span><span style="font-size:14pt;text-align:justify;text-indent:2em">, <span style="text-align:justify;text-indent:2em;font-size:20px">who is the leader of the CoLab, is a professor in Beihang University. She was a visiting professor in Microsoft Research Asia. She used to work with Prof. Shuicheng Yan in National University of Singapore. She obtained Ph.D. degree from Institute of Automation, Chinese Academy of Sciences (CASIA), under the supervision of Prof. Hanqing Lu. She obtained Bachelor degree from Advanced Class of Beijing Institute of Technology (BIT) .</span></span></span></p> 
<p style="text-align:center;text-indent:0px"><img src="../../images/2023-03/5ab40fc46c504a449956ffd7f76c6819.png" width="147" height="147"></p> 
<p style="text-indent:2em;font-size:14pt;text-align:justify"><a href="http://www.mohamed-elhoseiny.com/%20" style="text-decoration:underline;color:rgb( 84 , 141 , 212 );font-size:20px" rel="nofollow"></a></p> 
<p><a href="http://www.mohamed-elhoseiny.com/" rel="nofollow"><span style="font-family:'times new roman';color:rgb( 5 , 99 , 193 );text-decoration:underline;font-size:20px">Prof. Mohamed Elhoseiny</span></a><span style="color:#0563c1;font-family:'times new roman'">&nbsp;</span><span style="font-size:14pt;text-align:justify;text-indent:2em">&nbsp;<span style="text-align:justify;text-indent:2em;font-size:20px">is an assistant professor of Computer Science at KAUST. Previously, he was a visiting Faculty at Stanford Computer Science department (2019-2020), Visiting Faculty at Baidu Research (2019), Postdoc researcher at Facebook AI Research (2016-2019). His primary research interest is in computer vision and especially in efficient multimodal learning with limited data in zero/few-shot learning and Vision &amp; Language. He is also interested in Affective AI and especially to understand and generate novel art and fashion. He received an NSF Fellowship in 2014 and the Doctoral Consortium award at CVPR’16.</span></span></p> 
<p style="text-align:center;text-indent:0px"><img src="../../images/2023-03/56e231bc7ccd485296de5d3e900a9cec.jpeg" width="143" height="143"></p> 
<p style="text-indent:2em;font-size:14pt;text-align:justify">Dr.<a href="https://hangz-nju-cuhk.github.io/" rel="nofollow"><span style="font-family:'times new roman';color:rgb( 5 , 99 , 193 );font-size:20px">Hang zhou</span></a><span style="color:#0563c1;font-family:'times new roman'">&nbsp;</span><span style="text-indent:2em;font-size:20px">is currently a senior researcher at Department of Computer Vision Technology (VIS), Baidu Inc. He obtained his Ph.D. degree fromMultimedia Lab (MMLab), The Chinese University of Hong Kong in 2021, supervised by Prof. Xiaogang WangandProf. Ziwei Liu. He received his bachelor's degree in Acoustics from the School of Physics atNanjing University (NJU)in 2017. His research interests include deep learning and its applications on audio-visual learning and face generation for virtual human.</span></p> 
                </div>
                </div>

            </div>
        </div>
    </div>
</div>

<!--========== FOOTER ==========-->
        <footer class="footer">
            <!-- Links -->
                <div class="content container">
                    <div class="row">
                        <div class="col-sm-4 col-xs-12 sm-margin-b-30 hidden-xs">
                            <img src="../../images/gsai_en_logo_white.png" style="height:60px">
                        </div>

                        <div class="col-sm-5 col-xs-12">
                            <!-- List -->
                            <ul class="list-unstyled footer-list">
                                <li class="footer-list-item">Email: <a href="#">gsai@ruc.edu.cn</a></li>
                                <li class="footer-list-item">Mobile: <a href="#">86-10-62511257</a></li>
                            </ul>
                            <!-- End List -->
                        </div>
                        <div class="col-sm-3 col-xs-12">
                            <!-- List -->
                            <ul class="list-unstyled footer-list">
                                    <li class="footer-list-item">Copyright©2020 Gaoling School of <br>Artificial Intelligence</li>
                            </ul>
                            <!-- End List -->
                        </div>
                    </div>
                    <!--// end row -->
                </div>
  
            <!-- End Links -->
        </footer>
        <!--========== END FOOTER ==========-->

        <!-- Back To Top -->
        <a href="javascript:void(0);" class="js-back-to-top back-to-top">Top</a>
<script src="../../js/menuscript.js"></script>
<script>
$(function(){
		$("#desc").autoIMG();
	});
</script>

<script>	
	window.onload=function(){  
		
	}			
	</script>
<script type="text/javascript">
	jQuery.ajax({
		url: '/wm/api/visit/write/article',
		type: 'get',
		data: {
			siteID: 'b789c5741b814b2998e36b9a58c98f96',
			articleID:'d6886bd0d67445e6980555c9f7ecb7fe',
			articleName:encodeURIComponent("Upcoming Event | Joint Workshop on Adcances in Al")
		}
	})
</script>

    </body>
</html><script type='text/javascript' src='../../g_style/g_article.js'></script>
</body></html>